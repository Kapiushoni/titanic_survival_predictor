{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект \"Титанік\": Прогнозування виживання пасажирів\n",
    "\n",
    "**Мета:** Побудувати модель машинного навчання, яка прогнозує, чи вижив пасажир, на основі його даних (клас, вік, стать тощо)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Імпорт бібліотек\n",
    "\n",
    "Імпортуємо `pandas` та `numpy` для роботи з даними, `matplotlib` та `seaborn` для візуалізації, та `sklearn` для побудови моделі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Завантаження та аналіз даних (EDA)\n",
    "\n",
    "Ми використаємо вбудований набір даних 'titanic' з бібліотеки `seaborn`. Це значно спрощує завантаження."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Завантажуємо дані\n",
    "data = sns.load_dataset('titanic')\n",
    "\n",
    "# Дивимось на перші 5 рядків\n",
    "print(\"Перші 5 рядків даних:\")\n",
    "print(data.head())\n",
    "\n",
    "# Отримуємо загальну інформацію про стовпці та типи даних\n",
    "print(\"\\nІнформація про дані:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Пошук пропущених значень\n",
    "\n",
    "Це найважливіший крок у цьому проекті. Ми бачимо, що у `age` (вік) та `deck` (палуба) багато пропусків."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nКількість пропущених значень:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Візуалізація\n",
    "\n",
    "Подивімося, як стать та клас каюти впливали на виживання."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Вплив статі на виживання\n",
    "sns.countplot(x='survived', hue='sex', data=data, ax=ax1)\n",
    "ax1.set_title('Виживання за статтю')\n",
    "ax1.set_xticklabels(['Загинув', 'Вижив'])\n",
    "\n",
    "# Вплив класу на виживання\n",
    "sns.countplot(x='survived', hue='pclass', data=data, ax=ax2)\n",
    "ax2.set_title('Виживання за класом')\n",
    "ax2.set_xticklabels(['Загинув', 'Вижив'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Обробка та підготовка даних (Feature Engineering)\n",
    "\n",
    "Зараз ми \"очистимо\" дані, щоб модель могла їх зрозуміти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вибираємо ознаки (features), які будемо використовувати\n",
    "# 'survived' - це наша ціль (y), решта - ознаки (X)\n",
    "features = ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
    "target = 'survived'\n",
    "\n",
    "# Створюємо копії, щоб не змінювати оригінальні дані\n",
    "X = data[features].copy()\n",
    "y = data[target].copy()\n",
    "\n",
    "# --- 1. Обробка пропущених значень ---\n",
    "\n",
    "# 'age': Заповнюємо пропущений вік медіанним (середнім) значенням\n",
    "# strategy='median' - стійкий до викидів\n",
    "age_imputer = SimpleImputer(strategy='median')\n",
    "X['age'] = age_imputer.fit_transform(X[['age']])\n",
    "\n",
    "# 'embarked': Заповнюємо пропущений порт посадки модою (найчастішим значенням)\n",
    "embarked_imputer = SimpleImputer(strategy='most_frequent')\n",
    "X['embarked'] = embarked_imputer.fit_transform(X[['embarked']])\n",
    "\n",
    "print(\"Дані після заповнення пропусків:\")\n",
    "X.info()\n",
    "\n",
    "# --- 2. Кодування категоріальних ознак ---\n",
    "\n",
    "# Моделі не розуміють текст ('male', 'female', 'S', 'C', 'Q'). Треба перетворити їх на числа.\n",
    "\n",
    "# 'sex': Перетворюємо 'male' -> 1, 'female' -> 0\n",
    "X['sex'] = X['sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "# 'embarked': Використовуємо One-Hot Encoding, щоб уникнути помилкового порядку (S > C > Q)\n",
    "X = pd.get_dummies(X, columns=['embarked'], drop_first=True)\n",
    "\n",
    "print(\"\\nДані після кодування:\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Тренування моделі\n",
    "\n",
    "Нарешті, ми готові розділити дані та натренувати модель. Ми використаємо `RandomForestClassifier` — це потужна та надійна модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Розділяємо дані на тренувальну та тестову вибірки (80% / 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Розмір тренувальної вибірки: {X_train.shape[0]}\")\n",
    "print(f\"Розмір тестової вибірки: {X_test.shape[0]}\")\n",
    "\n",
    "# Ініціалізуємо модель\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
    "\n",
    "# Тренуємо модель\n",
    "print(\"\\nТренування моделі...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Модель натреновано.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Оцінка моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Робимо передбачення на тестових даних\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Розраховуємо точність\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nТочність моделі на тестовій вибірці: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Будуємо матрицю помилок\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Загинув', 'Вижив'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp.plot(ax=ax, cmap='Blues')\n",
    "plt.title(\"Матриця помилок для 'Титаніка'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Висновок\n",
    "\n",
    "Ми успішно побудували повний ML-пайплайн:\n",
    "1.  Завантажили дані.\n",
    "2.  Проаналізували їх та візуалізували.\n",
    "3.  **Очистили дані:** заповнили пропущений вік та порт посадки, перетворили текстові дані на числові.\n",
    "4.  Натренували модель `RandomForestClassifier`.\n",
    "5.  Досягли точності **~80%**.\n",
    "\n",
    "Матриця помилок показує, що модель досить добре передбачає обидва класи (і тих, хто вижив, і тих, хто загинув), хоча й припускається помилок."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
